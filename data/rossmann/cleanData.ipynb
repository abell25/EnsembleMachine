{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "from dateutil import parser\n",
    "from time import time\n",
    "\n",
    "import imp\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/tony/code/python/notebooks/MyLib/EnsembleMachine')\n",
    "\n",
    "import date_feature_extractor\n",
    "imp.reload(date_feature_extractor)\n",
    "from date_feature_extractor import DateFeatureExtractor\n",
    "\n",
    "import categorical_feature_extractor\n",
    "imp.reload(categorical_feature_extractor)\n",
    "from categorical_feature_extractor import CategoricalFeatureExtraction\n",
    "\n",
    "import train_test_data_loader\n",
    "imp.reload(train_test_data_loader)\n",
    "from train_test_data_loader import TrainTestDataLoader\n",
    "\n",
    "import feature_selection\n",
    "imp.reload(feature_selection)\n",
    "from feature_selection import FeatureSelection\n",
    "\n",
    "import problem_type\n",
    "imp.reload(problem_type)\n",
    "from problem_type import ProblemType\n",
    "\n",
    "#for forward/backward regression\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, LogisticRegressionCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:logger loaded!\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logging.info(\"logger loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "store_df = pd.read_csv('store.csv').drop(['PromoInterval'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the data from the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed in 0.022304058075 seconds!\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "dataLoader = TrainTestDataLoader('train.csv', 'test.csv', train_labels_column='Sales', test_ids_column='Id')\n",
    "dataLoader.cleanData(max_onehot_limit=200)\n",
    "X, X_sub, y = dataLoader.getTrainTestData()\n",
    "print('completed in {0} seconds!'.format(time()-t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def loadData(train_df, test_df, id_col='Id', label_col='Sales'):\n",
    "\n",
    "    train_labels = train_df[label_col].values\n",
    "    train_df.drop(label_col, axis=1, inplace=True)\n",
    "\n",
    "    test_ids = test_df[id_col].values\n",
    "    test_df.drop(id_col, axis=1, inplace=True)\n",
    "\n",
    "    # Convert 'object' columns to one-hot encoding\n",
    "    # Ordinal encoding is also available for 'object/int/float' columns.\n",
    "    print('loading one-hot categories [\"StateHoliday\"]')\n",
    "    categoricalFeatureExtractor = CategoricalFeatureExtraction()\n",
    "    categoricalFeatureExtractor.convertColumnsToOneHot([train_df, test_df], ['StateHoliday'])\n",
    "\n",
    "    #Convert date columns to date features (year, month, day, day-of-week, etc.)\n",
    "    print('loading date features for \"Date\"')\n",
    "    dateFeatureExtractor = DateFeatureExtractor()\n",
    "    train_df = dateFeatureExtractor.createFeaturesFromDateColumns(train_df, ['Date'])\n",
    "    test_df = dateFeatureExtractor.createFeaturesFromDateColumns(test_df, ['Date'])\n",
    "\n",
    "    print('imputing null values with 0s')\n",
    "    train_df = train_df.fillna(0)\n",
    "    test_df = test_df.fillna(0)\n",
    "\n",
    "    categoricalFeatureExtractor = CategoricalFeatureExtraction()\n",
    "    categoricalFeatureExtractor.removeUnsharedColumns([train_df, test_df])\n",
    "\n",
    "    #os.mkdir('autoML_rossmann')\n",
    "    train_df.to_csv('rossmann_clean_train.csv', index=False)\n",
    "    test_df.to_csv('rossmann_clean_test.csv', index=False)\n",
    "    pd.DataFrame({'y': train_labels}).to_csv('rossmann_clean_trainLabels.csv', index=False)\n",
    "    pd.DataFrame({'id': test_ids}).to_csv('rossmann_clean_testIds', index=False)\n",
    "\n",
    "    return train_df, test_df, train_labels, test_ids\n",
    "\n",
    "#train_df, test_df, train_labels, test_ids = loadData(train_df, test_df, id_col='Id', label_col='Sales')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1017209, 14), (41088, 14), (1017209,))"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, X_sub.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features\n"
     ]
    }
   ],
   "source": [
    "print \"Extracting features\"\n",
    "featureSelection = FeatureSelection(lower_is_better=True, method='all', X=X, y=y, clf=LogisticRegressionCV(), problem_type='classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1017209, 14), (1017209, 14))"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_all = featureSelection.allSelection(X)\n",
    "X_all.shape, X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idxs_forwards = [0,2,3,8]\n",
    "X_forwards, X_sub_forwards = X[:,idxs_forwards], X_sub[:,idxs_forwards]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import feature_selection\n",
    "imp.reload(feature_selection)\n",
    "from feature_selection import FeatureSelection\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "#X_backwards, X_sub_backwards = FeatureSelection.backwards(X, y, X_sub, RandomForestRegressor(n_estimators=10, n_jobs=5), ProblemType.RMSPE, lower_is_better=True, clf_names=dataLoader.train_df.columns)\n",
    "X_imp, X_sub_imp = FeatureSelection.getFeatureImportanceColumns(X, y, X_sub, RandomForestRegressor(n_estimators=10, n_jobs=5), col_names=dataLoader.train_df.columns, total_importance=0.90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 10, 3]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from random import shuffle\n",
    "\n",
    "    N = X.shape[1]\n",
    "    percent = 0.20\n",
    "    idxs = range(N)\n",
    "    shuffle(idxs)\n",
    "    max_idx = int(max(1, np.round(percent*N)))\n",
    "    idxs[:max_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19486272021352932"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "rf = RandomForestRegressor(n_jobs=7, n_estimators=20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_imp, y, train_size=0.90)\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "ProblemType.RMSPE(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20020303039544898"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "rf = RandomForestRegressor(n_jobs=7, n_estimators=10)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.90)\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "ProblemType.RMSPE(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def submitPreds(filename, y_sub):\n",
    "    sub_df = pd.read_csv('sample_submission.csv')\n",
    "    sub_df.Sales = y_sub\n",
    "    sub_df.to_csv(filename, index=False)\n",
    "    \n",
    "y_sub = rf.predict(X_sub_forwards)\n",
    "submitPreds('first_forwards5_rf20trees__16148.csv', y_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.39010083,  0.01500248,  0.50112696,  0.07976783,  0.01335265,\n",
       "        0.00064927])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.90)\n",
    "rf = RandomForestRegressor(n_jobs=7, n_estimators=10)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 'Open', 0.46035955648582105),\n",
       " (0, 'Store', 0.37459639795312716),\n",
       " (3, 'Promo', 0.073089276548274074),\n",
       " (9, 'Date_dayofyear', 0.028606382392950762),\n",
       " (5, 'Date_day', 0.017461663441706535),\n",
       " (1, 'DayOfWeek', 0.016110280378141367),\n",
       " (8, 'Date_dayofweek', 0.015085839838105741),\n",
       " (7, 'Date_year', 0.0049794525869336307),\n",
       " (6, 'Date_month', 0.0044617401327617023),\n",
       " (4, 'SchoolHoliday', 0.0036706046845585661),\n",
       " (10, 'StateHoliday=0', 0.0011192892528948709),\n",
       " (11, 'StateHoliday=a', 0.00031582115377476173),\n",
       " (12, 'StateHoliday=b', 0.0001367929834621341),\n",
       " (13, 'StateHoliday=c', 6.9021674876742197e-06)]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuples = sorted(zip(range(len(rf.feature_importances_)), dataLoader.train_df.columns, rf.feature_importances_), key=lambda x: x[2], reverse=True)\n",
    "tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 'Open', 0.46035955648582105),\n",
       " (0, 'Store', 0.37459639795312716),\n",
       " (3, 'Promo', 0.073089276548274074),\n",
       " (9, 'Date_dayofyear', 0.028606382392950762),\n",
       " (5, 'Date_day', 0.017461663441706535)]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_imp, max_imp = 0.0, 0.95\n",
    "trunc_tuples = []\n",
    "for idx, col, col_imp in tuples:\n",
    "    sum_imp += col_imp\n",
    "    trunc_tuples.append((idx, col, col_imp))\n",
    "    if sum_imp >= max_imp:\n",
    "        break\n",
    "trunc_tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
