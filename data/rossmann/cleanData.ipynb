{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "from dateutil import parser\n",
    "from time import time\n",
    "\n",
    "import imp\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "\n",
    "import date_feature_extractor\n",
    "imp.reload(date_feature_extractor)\n",
    "from date_feature_extractor import DateFeatureExtractor\n",
    "\n",
    "import categorical_feature_extractor\n",
    "imp.reload(categorical_feature_extractor)\n",
    "from categorical_feature_extractor import CategoricalFeatureExtraction\n",
    "\n",
    "import train_test_data_loader\n",
    "imp.reload(train_test_data_loader)\n",
    "from train_test_data_loader import TrainTestDataLoader\n",
    "\n",
    "import feature_selection\n",
    "imp.reload(feature_selection)\n",
    "from feature_selection import FeatureSelection\n",
    "\n",
    "import problem_type\n",
    "imp.reload(problem_type)\n",
    "from problem_type import ProblemType\n",
    "\n",
    "import model_library\n",
    "imp.reload(model_library)\n",
    "from model_library import ModelLibrary\n",
    "\n",
    "#for forward/backward regression\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, LogisticRegressionCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:logger loaded!\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logging.info(\"logger loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/cygdrive/c/Users/anthony/PycharmProjects/EnsembleMachine/data/rossmann\n"
     ]
    }
   ],
   "source": [
    "#train_df = pd.read_csv('train.csv')\n",
    "#test_df = pd.read_csv('test.csv')\n",
    "#store_df = pd.read_csv('store.csv').drop(['PromoInterval'], axis=1, inplace=True)\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the data from the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train_test_data_loader:reading train file train_100.csv\n",
      "INFO:train_test_data_loader:reading test file test_100.csv\n",
      "INFO:train_test_data_loader:extracting train labels from train_df[Sales]\n",
      "DEBUG:root:processing column: Store of type int64\n",
      "ERROR:train_test_data_loader:pandas type \"int64\" is not known!\n",
      "DEBUG:root:processing column: DayOfWeek of type int64\n",
      "ERROR:train_test_data_loader:pandas type \"int64\" is not known!\n",
      "DEBUG:root:processing column: Date of type object\n",
      "INFO:root:loading Date as a date\n",
      "DEBUG:root:processing column: Customers of type int64\n",
      "DEBUG:root:processing column: Open of type int64\n",
      "ERROR:train_test_data_loader:pandas type \"int64\" is not known!\n",
      "DEBUG:root:processing column: Promo of type int64\n",
      "ERROR:train_test_data_loader:pandas type \"int64\" is not known!\n",
      "DEBUG:root:processing column: StateHoliday of type int64\n",
      "ERROR:train_test_data_loader:pandas type \"int64\" is not known!\n",
      "DEBUG:root:processing column: SchoolHoliday of type int64\n",
      "ERROR:train_test_data_loader:pandas type \"int64\" is not known!\n",
      "INFO:train_test_data_loader:Completed in 0 seconds!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed in 0.1571049690246582 seconds!\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "dataLoader = TrainTestDataLoader('train_100.csv', 'test_100.csv', train_labels_column='Sales', test_ids_column='Id')\n",
    "dataLoader.cleanData(max_onehot_limit=200)\n",
    "X, X_sub, y = dataLoader.getTrainTestData()\n",
    "print('completed in {0} seconds!'.format(time()-t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=71, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=4,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=409, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_library = ModelLibrary(is_classification=True, is_binary=False, is_large_scale=False)\n",
    "model_library.generateModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features\n"
     ]
    }
   ],
   "source": [
    "print(\"Extracting features\")\n",
    "featureSelection = FeatureSelection(lower_is_better=True, method='all', X=X, y=y, clf=LogisticRegressionCV(), problem_type='classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idxs_forwards = [0,2,3,8]\n",
    "X_forwards, X_sub_forwards = X[:,idxs_forwards], X_sub[:,idxs_forwards]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import feature_selection\n",
    "imp.reload(feature_selection)\n",
    "from feature_selection import FeatureSelection\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "#X_backwards, X_sub_backwards = FeatureSelection.backwards(X, y, X_sub, RandomForestRegressor(n_estimators=10, n_jobs=5), ProblemType.RMSPE, lower_is_better=True, clf_names=dataLoader.train_df.columns)\n",
    "X_imp, X_sub_imp = FeatureSelection.getFeatureImportanceColumns(X, y, X_sub, RandomForestRegressor(n_estimators=10, n_jobs=5), col_names=dataLoader.train_df.columns, total_importance=0.90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-27-89f2c7dc76a0>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-27-89f2c7dc76a0>\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    N = X.shape[1]\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "from random import shuffle\n",
    "\n",
    "    N = X.shape[1]\n",
    "    percent = 0.20\n",
    "    idxs = range(N)\n",
    "    shuffle(idxs)\n",
    "    max_idx = int(max(1, np.round(percent*N)))\n",
    "    idxs[:max_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19486272021352932"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "rf = RandomForestRegressor(n_jobs=7, n_estimators=20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_imp, y, train_size=0.90)\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "ProblemType.RMSPE(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20020303039544898"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "rf = RandomForestRegressor(n_jobs=7, n_estimators=10)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.90)\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "ProblemType.RMSPE(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def submitPreds(filename, y_sub):\n",
    "    sub_df = pd.read_csv('sample_submission.csv')\n",
    "    sub_df.Sales = y_sub\n",
    "    sub_df.to_csv(filename, index=False)\n",
    "    \n",
    "y_sub = rf.predict(X_sub_forwards)\n",
    "submitPreds('first_forwards5_rf20trees__16148.csv', y_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.39010083,  0.01500248,  0.50112696,  0.07976783,  0.01335265,\n",
       "        0.00064927])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.90)\n",
    "rf = RandomForestRegressor(n_jobs=7, n_estimators=10)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 'Open', 0.46035955648582105),\n",
       " (0, 'Store', 0.37459639795312716),\n",
       " (3, 'Promo', 0.073089276548274074),\n",
       " (9, 'Date_dayofyear', 0.028606382392950762),\n",
       " (5, 'Date_day', 0.017461663441706535),\n",
       " (1, 'DayOfWeek', 0.016110280378141367),\n",
       " (8, 'Date_dayofweek', 0.015085839838105741),\n",
       " (7, 'Date_year', 0.0049794525869336307),\n",
       " (6, 'Date_month', 0.0044617401327617023),\n",
       " (4, 'SchoolHoliday', 0.0036706046845585661),\n",
       " (10, 'StateHoliday=0', 0.0011192892528948709),\n",
       " (11, 'StateHoliday=a', 0.00031582115377476173),\n",
       " (12, 'StateHoliday=b', 0.0001367929834621341),\n",
       " (13, 'StateHoliday=c', 6.9021674876742197e-06)]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuples = sorted(zip(range(len(rf.feature_importances_)), dataLoader.train_df.columns, rf.feature_importances_), key=lambda x: x[2], reverse=True)\n",
    "tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 'Open', 0.46035955648582105),\n",
       " (0, 'Store', 0.37459639795312716),\n",
       " (3, 'Promo', 0.073089276548274074),\n",
       " (9, 'Date_dayofyear', 0.028606382392950762),\n",
       " (5, 'Date_day', 0.017461663441706535)]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_imp, max_imp = 0.0, 0.95\n",
    "trunc_tuples = []\n",
    "for idx, col, col_imp in tuples:\n",
    "    sum_imp += col_imp\n",
    "    trunc_tuples.append((idx, col, col_imp))\n",
    "    if sum_imp >= max_imp:\n",
    "        break\n",
    "trunc_tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
